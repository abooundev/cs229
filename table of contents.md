# cs229 note1

## Supervised learning

### Part I Linear Regression

1. LMS algorithm
2. The normal equations
   1.  Matrix derivatives
   2. Least squares revisited
3. Probabilistic interpretation
4. Locally weighted linear regression



### Part II Classification and logistic regression

5. Logistic regression
6. Digression: The perceptron learning algorithn
7. Another algorithm for maximizing l(Î¸)



### Part III Generalized Linear Models

8. The exponential family
9. Constructing GLMs
   1. Ordinary Least Squares
   2. Logistic Regression
   3. Softmax Regression

# cs229 note2

### Part IV Generative Learning algorithms

1. Gaussian discriminant analysis
   1. The multivariate normal distribution
   2. The Gaussian Discriminant Analysis model
   3. Discussion: GDA and logistic regression

2. Naive Bayes
   1. Laplace smoothing
   2. Event models for text classification



# cs229 note3

### Part V Kernel Methods

1. Kernel Methods
   1. Feature maps
   2. LMS (least mean squares) with features
   3. LMS with the kernel trick
   4. Properties of kernels

### Part VI Support Vector Machines

2. Margins: Intuition
3. Notation
4. Functional and geometric margins
5. The optimal margin classifier
6. Lagrange duality (optional reading)
7. Optimal margin classifiers
8. Regularization and the non-separable case (optional reading)
9. The SMO algorithm (optional reading)
   1.  Coordinate ascent
   2. SMO

